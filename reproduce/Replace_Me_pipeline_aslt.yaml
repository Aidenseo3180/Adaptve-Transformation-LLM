# RILD Configuration Example
# Residual-Informed Low-Rank Decomposition for efficient LLM compression

# Method selection - use "rild" for Residual-Informed Low-Rank Decomposition
method: "rild"

# Model and dataset configuration
model_path: "meta-llama/Meta-Llama-3-8B-Instruct"  # or your model path
dataset: "Open-Orca/SlimOrca"
dataset_column: "text"
dataset_subset: "train"
dataset_size: 4000

# Processing parameters
batch_size: 4
max_length: 1024
use_4bit: True
token: null  # Add your HuggingFace token if needed

# Layer selection parameters
layers_to_skip: 4  # Number of layers in each block to compress
num_A: 1  # Number of compression blocks
merge_consecutive: False
distances_path: null  # Will be auto-generated if null

# RILD-specific parameters
rank: 256  # Low-rank dimension (32/4096 = 0.78% compression)
loss: "cosine"  # Loss function for optimization ("cosine" or "mse")
accurate: False  # Set to true for more accurate but memory-intensive computation

# Optimization parameters (inherited from original method)
solver: "adam"
diag: False
two_vectors: False
thri: False

# Output parameters
save_path: null  # Will be auto-generated if null
save_transform_only: False

# Evaluation parameters
tasks: "default"

# Advanced RILD parameters (optional, uses defaults if not specified)
# num_epochs: 15 (training epochs for low-rank optimization)
# lr: 1e-4 (learning rate for Adam optimizer)
# weight_decay: 1e-5 (L2 regularization for stability)
# batch_size_optim: 1024 (batch size for optimization)

# Example configurations for different compression levels:

# Conservative compression (rank=64, ~1.5% of original parameters):
# rank: 64
# Expected: 97% FLOP reduction, 98%+ performance retention

# Balanced compression (rank=32, ~0.8% of original parameters):
# rank: 32  
# Expected: 98.5% FLOP reduction, 95%+ performance retention

# Aggressive compression (rank=16, ~0.4% of original parameters):
# rank: 16
# Expected: 99.2% FLOP reduction, 90%+ performance retention

# Ultra compression (rank=8, ~0.2% of original parameters):
# rank: 8
# Expected: 99.6% FLOP reduction, might need healing for performance recovery