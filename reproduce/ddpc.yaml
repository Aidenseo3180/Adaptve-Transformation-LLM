method: "ddpc"
model_path: "meta-llama/Meta-Llama-3-8B-Instruct"
dataset: "Open-Orca/SlimOrca"
dataset_column: "text"
batch_size: 8
max_length: 1024
layers_to_skip: 8
dataset_size: 8000
dataset_subset: "train"
use_4bit: False
save_path: null
distances_path: "distances.pth"
num_A: 1
merge_consecutive: False

# DDPC specific parameters
num_compensation_points: 3  # Number of layers to distribute compensation
compensation_epochs: 10     # Training epochs for each compensation
compensation_lr: 0.0001     # Learning rate for compensation training

# # Evaluation parameters
# tasks:
#   winogrande:
#     fewshots: 5
#   boolq:
#     fewshots: 0
#   piqa:
#     fewshots: 0
#   sciq:
#     fewshots: 0