# Multi-Linear Block Replacement (MLBR) Configuration

method: "mlbr"  # Use the new multi-linear block replacement method
model_path: "meta-llama/Meta-Llama-3-8B-Instruct"
dataset: "Open-Orca/SlimOrca"
dataset_column: "text"
batch_size: 4
max_length: 512
layers_to_skip: 4
dataset_size: 4000  # Increased for better linear layer learning
dataset_subset: "train"
use_4bit: True
save_path: null
token: null  # Add your HuggingFace token here if needed

# Distance computation parameters
distances_path: "distances.pth"  # Will auto-generate if not provided
num_A: 1
merge_consecutive: False

# MLBR-specific parameters
regularization: 1e-6  # Ridge regularization strength for solving linear systems

# Evaluation parameters (optional)
tasks:
  boolq:
    fewshots: 0
  lambada_openai:
    fewshots: 0

# Debug settings
verbose: True
save_intermediate_results: False